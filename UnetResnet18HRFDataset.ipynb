{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mfFM8x73jQ9-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import skimage \n",
    "\n",
    "#dataloader\n",
    "\n",
    "class HRFDataset(Dataset):\n",
    "    def __init__(self, image_paths, target_paths, train=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "\n",
    "    def transform(self, image, mask):\n",
    "    # Resize\n",
    "\n",
    "        imageTransform= transforms.Compose([\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "        ])\n",
    "\n",
    "        maskTransform= transforms.Compose([\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "        ])\n",
    "\n",
    "        image= imageTransform(image)\n",
    "        mask= maskTransform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        mask = Image.open(self.target_paths[index])\n",
    "        x, y = self.transform(image, mask)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "    \n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "daYTpwDnjQ-D",
    "outputId": "af34d158-5287-40f1-a279-c20065c0093b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content/drive/My Drive/retinanet/dataset/images/01_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/01_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/01_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/02_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/02_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/02_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/03_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/03_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/03_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/04_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/04_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/04_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/05_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/05_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/05_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/06_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/06_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/06_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/07_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/07_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/07_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/08_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/08_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/08_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/09_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/09_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/09_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/10_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/10_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/10_h.jpg', '/content/drive/My Drive/retinanet/dataset/images/11_dr.JPG', '/content/drive/My Drive/retinanet/dataset/images/11_g.jpg', '/content/drive/My Drive/retinanet/dataset/images/11_h.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Creating training paths for dataset\n",
    "extra_val=\"0\"\n",
    "train_dir=\"/content/drive/My Drive/retinanet/dataset/images/\"\n",
    "mask_dir=\"/content/drive/My Drive/retinanet/dataset/mask/\"\n",
    "train_array=[]\n",
    "val_array=[]\n",
    "for i in range(1,12):\n",
    "    if(i<10):\n",
    "        train_array.append(train_dir+extra_val+str(i)+\"_dr.JPG\")\n",
    "        train_array.append(train_dir+extra_val+str(i)+\"_g.jpg\")\n",
    "        train_array.append(train_dir+extra_val+str(i)+\"_h.jpg\")\n",
    "    else:\n",
    "        train_array.append(train_dir+str(i)+\"_dr.JPG\")\n",
    "        train_array.append(train_dir+str(i)+\"_g.jpg\")\n",
    "        train_array.append(train_dir+str(i)+\"_h.jpg\")\n",
    "\n",
    "for i in range(1,12):\n",
    "    if(i<10):\n",
    "        val_array.append(mask_dir+extra_val+str(i)+\"_dr_mask.tif\")\n",
    "        val_array.append(mask_dir+extra_val+str(i)+\"_g_mask.tif\")\n",
    "        val_array.append(mask_dir+extra_val+str(i)+\"_h_mask.tif\")\n",
    "    else:\n",
    "        val_array.append(mask_dir+str(i)+\"_dr_mask.tif\")\n",
    "        val_array.append(mask_dir+str(i)+\"_g_mask.tif\")\n",
    "        val_array.append(mask_dir+str(i)+\"_h_mask.tif\")\n",
    "\n",
    "# Creating Validation paths dataset\n",
    "\n",
    "\n",
    "\n",
    "valid_image=[]\n",
    "valid_mask=[]\n",
    "for i in range(12,16):\n",
    "    if(i<10):\n",
    "        valid_image.append(train_dir+extra_val+str(i)+\"_dr.JPG\")\n",
    "        valid_image.append(train_dir+extra_val+str(i)+\"_g.jpg\")\n",
    "        valid_image.append(train_dir+extra_val+str(i)+\"_h.jpg\")\n",
    "    else:\n",
    "        valid_image.append(train_dir+str(i)+\"_dr.JPG\")\n",
    "        valid_image.append(train_dir+str(i)+\"_g.jpg\")\n",
    "        valid_image.append(train_dir+str(i)+\"_h.jpg\")\n",
    "\n",
    "for i in range(12,16):\n",
    "    if(i<10):\n",
    "        valid_mask.append(mask_dir+extra_val+str(i)+\"_dr_mask.tif\")\n",
    "        valid_mask.append(mask_dir+extra_val+str(i)+\"_g_mask.tif\")\n",
    "        valid_mask.append(mask_dir+extra_val+str(i)+\"_h_mask.tif\")\n",
    "    else:\n",
    "        valid_mask.append(mask_dir+str(i)+\"_dr_mask.tif\")\n",
    "        valid_mask.append(mask_dir+str(i)+\"_g_mask.tif\")\n",
    "        valid_mask.append(mask_dir+str(i)+\"_h_mask.tif\")\n",
    "\n",
    "train_set= HRFDataset(train_array,val_array)\n",
    "val_set= HRFDataset(valid_image,valid_mask)\n",
    "\n",
    "print train_set.image_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qmG5ZhcdjQ-J",
    "outputId": "fd6f8f52-b93e-4fac-a04e-391339d05286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 33, 'val': 12}"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x].image_paths) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0B5D9rxEjQ-R"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "base_model = models.resnet18(pretrained=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TeprDfmojQ-V"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = base_model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7IjXJl5ujQ-Y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "class ResNetUNet(nn.Module):\n",
    "  \n",
    "    def up(self,prev_features, layer, layer_conv, up_conv):\n",
    "\n",
    "      layer=layer_conv(layer)\n",
    "      prev_features=torch.cat([prev_features,layer],dim=1)\n",
    "      prev_features=up_conv(prev_features)\n",
    "      return self.upsample(prev_features)\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super(ResNetUNet,self).__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())                \n",
    "        \n",
    "        # Transfer Learning. Reusing Resnet Base Model Layers\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) \n",
    "        self.layer0_conv = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5])        \n",
    "        self.layer1_conv = convrelu(64, 64, 1, 0)       \n",
    "        self.layer2 = self.base_layers[5]         \n",
    "        self.layer2_conv = convrelu(128, 128, 1, 0)  \n",
    "        self.layer3 = self.base_layers[6]        \n",
    "        self.layer3_conv = convrelu(256, 256, 1, 0)  \n",
    "        self.layer4 = self.base_layers[7] \n",
    "        self.layer4_conv = convrelu(512, 512, 1, 0)  \n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        # Upconv Layers\n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #base model layers\n",
    "        layer0 = self.layer0(input)            \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        #uping\n",
    "        \n",
    "        layer4 = self.layer4_conv(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        x = self.up(x,layer3,self.layer3_conv,self.conv_up3)\n",
    "        x = self.up(x,layer2, self.layer2_conv, self.conv_up2)\n",
    "        x = self.up(x, layer1, self.layer1_conv, self.conv_up1)    \n",
    "        x = self.up(x, layer0, self.layer0_conv, self.conv_up0) \n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1887
    },
    "colab_type": "code",
    "id": "f5FCej91jQ-c",
    "outputId": "18791d90-7977-4d06-bc6e-610625ca6dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /usr/local/lib/python2.7/dist-packages (1.5.1)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "             ReLU-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
      "             ReLU-25          [-1, 128, 28, 28]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "           Conv2d-28          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-31          [-1, 128, 28, 28]               0\n",
      "           Conv2d-32          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "             ReLU-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-38          [-1, 128, 28, 28]               0\n",
      "           Conv2d-39          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-40          [-1, 256, 14, 14]             512\n",
      "             ReLU-41          [-1, 256, 14, 14]               0\n",
      "           Conv2d-42          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-43          [-1, 256, 14, 14]             512\n",
      "           Conv2d-44          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-47          [-1, 256, 14, 14]               0\n",
      "           Conv2d-48          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-49          [-1, 256, 14, 14]             512\n",
      "             ReLU-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-52          [-1, 256, 14, 14]             512\n",
      "             ReLU-53          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-54          [-1, 256, 14, 14]               0\n",
      "           Conv2d-55            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-56            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-57            [-1, 512, 7, 7]               0\n",
      "           Conv2d-58            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-59            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-60            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-63            [-1, 512, 7, 7]               0\n",
      "           Conv2d-64            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-65            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-66            [-1, 512, 7, 7]               0\n",
      "           Conv2d-67            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-68            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-69            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-70            [-1, 512, 7, 7]               0\n",
      "           Conv2d-71            [-1, 512, 7, 7]         262,656\n",
      "             ReLU-72            [-1, 512, 7, 7]               0\n",
      "         Upsample-73          [-1, 512, 14, 14]               0\n",
      "           Conv2d-74          [-1, 256, 14, 14]          65,792\n",
      "             ReLU-75          [-1, 256, 14, 14]               0\n",
      "           Conv2d-76          [-1, 512, 14, 14]       3,539,456\n",
      "             ReLU-77          [-1, 512, 14, 14]               0\n",
      "         Upsample-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          16,512\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "           Conv2d-81          [-1, 256, 28, 28]       1,474,816\n",
      "             ReLU-82          [-1, 256, 28, 28]               0\n",
      "         Upsample-83          [-1, 256, 56, 56]               0\n",
      "           Conv2d-84           [-1, 64, 56, 56]           4,160\n",
      "             ReLU-85           [-1, 64, 56, 56]               0\n",
      "           Conv2d-86          [-1, 256, 56, 56]         737,536\n",
      "             ReLU-87          [-1, 256, 56, 56]               0\n",
      "         Upsample-88        [-1, 256, 112, 112]               0\n",
      "           Conv2d-89         [-1, 64, 112, 112]           4,160\n",
      "             ReLU-90         [-1, 64, 112, 112]               0\n",
      "           Conv2d-91        [-1, 128, 112, 112]         368,768\n",
      "             ReLU-92        [-1, 128, 112, 112]               0\n",
      "         Upsample-93        [-1, 128, 224, 224]               0\n",
      "           Conv2d-94         [-1, 64, 224, 224]         110,656\n",
      "             ReLU-95         [-1, 64, 224, 224]               0\n",
      "           Conv2d-96          [-1, 1, 224, 224]              65\n",
      "================================================================\n",
      "Total params: 17,799,809\n",
      "Trainable params: 17,799,809\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 352.95\n",
      "Params size (MB): 67.90\n",
      "Estimated Total Size (MB): 421.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(1)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jAoiD-EkjQ-g"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    " \n",
    "\n",
    "\n",
    "def save_epoch_loss(loss, label, phase, lossMem):\n",
    "  lossMem['loss'+phase]+=loss.data.cpu().numpy()* label.size(0)\n",
    "\n",
    "\n",
    "def train_model(mode,optimizer,scheduler,num_epochs=15):\n",
    "  best_weights=copy.deepcopy(model.state_dict())\n",
    "  best_loss=1e10\n",
    "  for epoch in range(num_epochs):\n",
    "    print \"EPOCH\"\n",
    "    print '{}/{}'.format(epoch,num_epochs-1)\n",
    "    \n",
    "    ## training the model\n",
    "    scheduler.step()\n",
    "    model.train() #setting training mode on\n",
    "    lossMem = defaultdict(float)\n",
    "    \n",
    "    for inputs,labels in dataloaders['train']:\n",
    "      inputs = inputs.to(device)\n",
    "      labels= labels.to(device)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      with torch.set_grad_enabled(True): \n",
    "        outputs = model(inputs)\n",
    "\n",
    "        outputsFlat=outputs.view(-1)\n",
    "        labelsFlat= labels.view(-1)\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(outputsFlat, labelsFlat)\n",
    "        save_epoch_loss(loss,labels,'train', lossMem)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_loss= lossMem['losstrain']/10\n",
    "        \n",
    "        ## validation phase\n",
    "\n",
    "    if epoch_loss<best_loss:\n",
    "      print(\"saving best model\")\n",
    "      best_loss = epoch_loss\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    print \"Training Loss: {}\".format(lossMem['losstrain'])\n",
    "    print \"-\"*10\n",
    "\n",
    "  print('Final val loss: {:4f}'.format(best_loss))\n",
    "  # load best model weights\n",
    "  model.load_state_dict(best_model_wts)\n",
    "  return mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1139
    },
    "colab_type": "code",
    "id": "vkuaDoYNjQ-j",
    "outputId": "9500ecaf-9c23-4602-b55d-a39025b81504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "EPOCH\n",
      "0/14\n",
      "saving best model\n",
      "Training Loss: 27.6502408385\n",
      "----------\n",
      "EPOCH\n",
      "1/14\n",
      "Training Loss: 27.6505297422\n",
      "----------\n",
      "EPOCH\n",
      "2/14\n",
      "saving best model\n",
      "Training Loss: 27.6497926116\n",
      "----------\n",
      "EPOCH\n",
      "3/14\n",
      "Training Loss: 27.6503124237\n",
      "----------\n",
      "EPOCH\n",
      "4/14\n",
      "Training Loss: 27.6503201127\n",
      "----------\n",
      "EPOCH\n",
      "5/14\n",
      "saving best model\n",
      "Training Loss: 27.6496711373\n",
      "----------\n",
      "EPOCH\n",
      "6/14\n",
      "Training Loss: 27.6526566744\n",
      "----------\n",
      "EPOCH\n",
      "7/14\n",
      "Training Loss: 27.650824368\n",
      "----------\n",
      "EPOCH\n",
      "8/14\n",
      "Training Loss: 27.6499474049\n",
      "----------\n",
      "EPOCH\n",
      "9/14\n",
      "Training Loss: 27.6517448425\n",
      "----------\n",
      "EPOCH\n",
      "10/14\n",
      "saving best model\n",
      "Training Loss: 27.6492168903\n",
      "----------\n",
      "EPOCH\n",
      "11/14\n",
      "Training Loss: 27.6492430568\n",
      "----------\n",
      "EPOCH\n",
      "12/14\n",
      "Training Loss: 27.6507505178\n",
      "----------\n",
      "EPOCH\n",
      "13/14\n",
      "Training Loss: 27.6511119008\n",
      "----------\n",
      "EPOCH\n",
      "14/14\n",
      "Training Loss: 27.6507943273\n",
      "----------\n",
      "Final val loss: 2.764922\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 1\n",
    "\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# Freezing Backbone Layers\n",
    "for l in model.base_layers:\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-55)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)        \n",
    "        \n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ratinaunetresnet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
